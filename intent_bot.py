# -*- coding: utf-8 -*-
import json
import numpy as np
import random
from pythainlp.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
import google.generativeai as genai
import os

# =====================
# Load intent data
# =====================
with open("intents.json", encoding="utf-8") as file:
    intent_data = json.load(file)

# =====================
# Gemini config
# =====================
API_KEYS = os.getenv("GEMINI_API_KEYS").split(",")

MODELS_TO_TRY = [
    "gemini-2.5-flash-lite",
    "gemini-2.5-flash"
]

# =====================
# Prepare intent model
# =====================
patterns = []
tags = []
responses = {}

for intent in intent_data["intents"]:
    for pattern in intent["patterns"]:
        patterns.append(pattern)
        tags.append(intent["tag"])
    responses[intent["tag"]] = intent["responses"]

tokenized_patterns = [
    " ".join(word_tokenize(p, engine="newmm")) for p in patterns
]

vectorizer = TfidfVectorizer()
classifier = LogisticRegression(
    solver="lbfgs",
    max_iter=1000,
    multi_class="multinomial"
)
model = make_pipeline(vectorizer, classifier)
model.fit(tokenized_patterns, tags)

# =====================
# Intent prediction
# =====================
def predict_intent(user_input, threshold=0.5):
    tokenized_input = " ".join(word_tokenize(user_input, engine="newmm"))
    probs = model.predict_proba([tokenized_input])[0]
    idx = np.argmax(probs)
    confidence = probs[idx]

    if confidence >= threshold:
        return model.classes_[idx], confidence
    return None, confidence

# =====================
# Gemini with auto key + model switch
# =====================
def query_gemini(user_input):
    knowledge_base = json.dumps(intent_data, ensure_ascii=False, indent=2)

    prompt = f"""à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¹€à¸ˆà¹‰à¸²à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¸«à¸à¸´à¸‡à¸‚à¸­à¸‡à¹€à¸—à¸¨à¸šà¸²à¸¥ à¸„à¸­à¸¢à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¹à¸¥à¸°à¸£à¸±à¸šà¹€à¸£à¸·à¹ˆà¸­à¸‡à¸£à¹‰à¸­à¸‡à¹€à¸£à¸µà¸¢à¸™à¸”à¹‰à¸§à¸¢à¸„à¸§à¸²à¸¡à¸ªà¸¸à¸ à¸²à¸ž 
à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸‚à¸­à¸‡à¹€à¸—à¸¨à¸šà¸²à¸¥ (à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸ˆà¸²à¸ intents.json):
{knowledge_base}

à¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¸›à¸£à¸°à¸Šà¸²à¸Šà¸™: {user_input}

à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸š:
1. à¸«à¸²à¸à¸„à¸³à¸–à¸²à¸¡à¸•à¸£à¸‡à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™ 'patterns' à¹ƒà¸«à¹‰à¸”à¸¶à¸‡à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸ 'responses' à¸¡à¸²à¸›à¸£à¸°à¸¢à¸¸à¸à¸•à¹Œà¹ƒà¸Šà¹‰
2. à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸à¸£à¸°à¸Šà¸±à¸šà¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸à¸±à¸™à¹€à¸­à¸‡
3. à¹„à¸¡à¹‰à¸•à¹‰à¸­à¸‡à¸ªà¸§à¸±à¸ªà¸”à¸µà¸—à¸¸à¸à¸£à¸­à¸šà¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸šà¸à¹‡à¹„à¸”à¹‰
4. à¸«à¹‰à¸²à¸¡à¸šà¸­à¸à¸§à¹ˆà¸²à¸„à¸·à¸­à¸¥à¸¹à¸à¸„à¹‰à¸²à¸«à¸£à¸·à¸­à¸­à¸¢à¹ˆà¸²à¸‡à¸­à¸·à¹ˆà¸™ à¹ƒà¸«à¹‰à¹à¸—à¸™ User à¸§à¹ˆà¸²à¸„à¸¸à¸“
5. à¸•à¸­à¸šà¹ƒà¸«à¹‰à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢
6. à¸«à¹‰à¸²à¸¡à¸•à¸­à¸šà¹€à¸£à¸·à¹ˆà¸­à¸‡à¸¨à¸²à¸ªà¸™à¸² à¸à¸²à¸£à¹€à¸¡à¸·à¸­à¸‡ à¸žà¸£à¸°à¸¡à¸²à¸«à¸²à¸à¸©à¸±à¸•à¸£à¸´à¸¢à¹Œ 
"""

    for api_key in API_KEYS:
        genai.configure(api_key=api_key)

        for model_name in MODELS_TO_TRY:
            try:
                print(f"Trying key={api_key[:8]}... model={model_name}")

                gemini_model = genai.GenerativeModel(model_name)
                response = gemini_model.generate_content(prompt)

                if response and response.text:
                    return response.text.strip()

            except Exception as e:
                err = str(e).lower()

                # quota / limit / resource exhausted
                if "quota" in err or "limit" in err or "resource" in err:
                    print("Quota hit â†’ switching model/key")
                    continue

                print(f"Gemini error: {e}")
                continue

    return "à¸‚à¸­à¹‚à¸—à¸©à¸„à¹ˆà¸° à¸‚à¸“à¸°à¸™à¸µà¹‰à¸¡à¸µà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸³à¸™à¸§à¸™à¸¡à¸²à¸ à¸à¸£à¸¸à¸“à¸²à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸ à¸²à¸¢à¸«à¸¥à¸±à¸‡ ðŸ™"

# =====================
# Chatbot main logic
# =====================
def chatbot_response(user_input, threshold=0.5):
    intent, confidence = predict_intent(user_input, threshold)

    if intent and confidence >= threshold:
        return random.choice(responses[intent]) + f" (à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆ: {round(confidence, 2)})"
    else:
        return query_gemini(user_input)
